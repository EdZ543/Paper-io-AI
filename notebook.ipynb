{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pytorch torchvision torchaudio cudatoolkit = 11.3 - c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install numpy pandas matplotlib\n",
    "%pip install opencv-python keyboard Pillow pyautogui wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1055, 10)\n"
     ]
    }
   ],
   "source": [
    "import os, time, shutil, copy, uuid\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keyboard as kb\n",
    "from PIL import ImageGrab, ImageFilter\n",
    "import pyautogui\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets coordinates for bbox\n",
    "kb.wait('enter')\n",
    "\n",
    "currentMouseX, currentMouseY = pyautogui.position()\n",
    "print(f'({currentMouseX}, {currentMouseY})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX = (2, 113, 1275, 1027)\n",
    "DATA_DIR = 'data'\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.9\n",
    "STEP_SIZE = 7\n",
    "GAMMA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets data folder\n",
    "dirpath = Path('data')\n",
    "if dirpath.exists():\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "os.makedirs(os.path.join('data', 'w'))\n",
    "os.makedirs(os.path.join('data', 'a'))\n",
    "os.makedirs(os.path.join('data', 's'))\n",
    "os.makedirs(os.path.join('data', 'd'))\n",
    "os.makedirs(os.path.join('data', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoot_screen():\n",
    "    screenshot = ImageGrab.grab(bbox=BBOX)\n",
    "    return screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Exiting data collection!\n"
     ]
    }
   ],
   "source": [
    "kb.wait('enter')\n",
    "print('Starting data collection...')\n",
    "\n",
    "while True:\n",
    "    screenshot = shoot_screen()\n",
    "    filename = str(uuid.uuid4()) + '.jpg'\n",
    "\n",
    "    if kb.is_pressed('w'): dir = 'w'\n",
    "    elif kb.is_pressed('a'): dir = 'a'\n",
    "    elif kb.is_pressed('s'): dir = 's'\n",
    "    elif kb.is_pressed('d'): dir = 'd'\n",
    "    else: dir = 'none'\n",
    "\n",
    "    screenshot.save(f'data/{dir}/{filename}')\n",
    "\n",
    "    if kb.is_pressed('esc'):\n",
    "        print('Exiting data collection!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"paper-io-ai\", config={\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"momentum\": MOMENTUM,\n",
    "    \"step_size\": STEP_SIZE,\n",
    "    \"gamma\": GAMMA\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229])\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(DATA_DIR, data_transform)\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    data, [train_size, val_size])\n",
    "image_datasets = {\n",
    "    'train': train_data,\n",
    "    'val': val_data\n",
    "}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = data.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.get_device_name(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485])\n",
    "    std = np.array([0.229])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=EPOCHS):\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device) # load data to GPU\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # clear gradients for this training step\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            wandb.log({\"loss\": epoch_loss, \"acc\": epoch_acc})\n",
    "\n",
    "            # save the model if it is the best so far\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "    wandb.log({\"best_acc\": best_acc})\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_df = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(),\n",
    "                         lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_ft, step_size=STEP_SIZE, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                       exp_lr_scheduler, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    \"\"\"Shows predictions for a few images\"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():  # Reduces memory consumption for inference\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Returns the max output\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "\n",
    "                # // divides and only keeps the integer part\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, os.path.join(wandb.run.dir, 'model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_file = wandb.restore(\n",
    "    'model.pt', run_path=\"eddiezhuang/paper-io-ai/1o0dyh11\")\n",
    "\n",
    "model = torch.load(model_file.name)\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    screenshot = su.shoot_screen()\n",
    "    screenshot = su.data_transform(screenshot)\n",
    "    output = model(screenshot)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play in Real Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.wait('enter')\n",
    "print('Starting AI playing...')\n",
    "\n",
    "while True:\n",
    "    screenshot = su.shoot_screen()\n",
    "\n",
    "    kb.send('w')\n",
    "    kb.send('a')\n",
    "    kb.send('s')\n",
    "    kb.send('d')\n",
    "\n",
    "    if kb.is_pressed('esc'):\n",
    "        print('Exiting AI playing!')\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('behaviourclone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81f6084b0e7cce954e108fc0a0391af68c4181771aad5745dbccfd4b74c77fe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
